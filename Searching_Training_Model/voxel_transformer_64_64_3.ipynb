{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a10b97e-4a57-4c83-b0df-05dfa691bac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing .ipynb_checkpoints: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category '.ipynb_checkpoints' processed and saved to ./voxel_data_64643\\.ipynb_checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing airplane: 100%|█████████████████████████████████████████████████████████| 1000/1000 [04:00<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'airplane' processed and saved to ./voxel_data_64643\\airplane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing automobile: 100%|███████████████████████████████████████████████████████| 1000/1000 [05:35<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'automobile' processed and saved to ./voxel_data_64643\\automobile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bird: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [04:11<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'bird' processed and saved to ./voxel_data_64643\\bird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cat: 100%|██████████████████████████████████████████████████████████████| 1000/1000 [04:37<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'cat' processed and saved to ./voxel_data_64643\\cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing deer: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [04:05<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'deer' processed and saved to ./voxel_data_64643\\deer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dog: 100%|██████████████████████████████████████████████████████████████| 1000/1000 [04:28<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'dog' processed and saved to ./voxel_data_64643\\dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frog: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [04:21<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'frog' processed and saved to ./voxel_data_64643\\frog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing horse: 100%|████████████████████████████████████████████████████████████| 1000/1000 [05:06<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'horse' processed and saved to ./voxel_data_64643\\horse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ship: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [04:01<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'ship' processed and saved to ./voxel_data_64643\\ship\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing truck: 100%|████████████████████████████████████████████████████████████| 1000/1000 [05:15<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'truck' processed and saved to ./voxel_data_64643\\truck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_aedat_file(filename):\n",
    "    \"\"\"Read a single .aedat file and return parsed data\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        header_lines = []\n",
    "        while True:\n",
    "            pos = f.tell()\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                raise ValueError(f\"No binary data section found in file {filename}, please check file format\")\n",
    "\n",
    "            try:\n",
    "                decoded_line = line.decode('ascii', errors='strict')\n",
    "            except UnicodeDecodeError:\n",
    "                # Unable to decode ASCII, means this is the start of binary data\n",
    "                f.seek(pos)\n",
    "                break\n",
    "\n",
    "            stripped_line = decoded_line.strip()\n",
    "            if stripped_line.startswith('#'):\n",
    "                header_lines.append(stripped_line)\n",
    "            else:\n",
    "                f.seek(pos)\n",
    "                break\n",
    "\n",
    "        data_start_index = f.tell()  # Data section start offset\n",
    "        data = f.read()\n",
    "\n",
    "    event_size = 8\n",
    "    num_events = len(data) // event_size\n",
    "\n",
    "    addresses = []\n",
    "    timestamps = []\n",
    "    xs = []\n",
    "    ys = []\n",
    "    polarities = []\n",
    "\n",
    "    for i in range(num_events):\n",
    "        event_data = data[i * event_size:(i + 1) * event_size]\n",
    "        # Parse address and timestamp in big-endian order\n",
    "        address, t = struct.unpack('>ii', event_data)\n",
    "        polarity = address & 1\n",
    "        x = (address >> 1) & 0x7F\n",
    "        y = (address >> 8) & 0x7F\n",
    "\n",
    "        addresses.append(address)\n",
    "        timestamps.append(t)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        polarities.append(polarity)\n",
    "\n",
    "    return {\n",
    "        'header': header_lines,\n",
    "        'addresses': addresses,\n",
    "        'timestamps': timestamps,\n",
    "        'xs': xs,\n",
    "        'ys': ys,\n",
    "        'polarities': polarities\n",
    "    }\n",
    "\n",
    "\n",
    "def process_and_save_voxel(input_base_folder, output_base_folder, grid_size=(64, 64, 3)):\n",
    "    \"\"\"\n",
    "    Process all .aedat files in category folders, convert event data to voxel representation and save as PyTorch tensors.\n",
    "\n",
    "    Parameters:\n",
    "        input_base_folder (str): Input folder path containing .aedat files organized by category.\n",
    "        output_base_folder (str): Output folder path where processed voxel tensors will be saved.\n",
    "        grid_size (tuple): Resolution of voxel grid, default (32, 32, 32).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_base_folder):\n",
    "        os.makedirs(output_base_folder)\n",
    "\n",
    "    # Iterate through category folders\n",
    "    for class_folder in os.listdir(input_base_folder):\n",
    "        input_folder = os.path.join(input_base_folder, class_folder)\n",
    "        output_folder = os.path.join(output_base_folder, class_folder)\n",
    "\n",
    "        if not os.path.isdir(input_folder):\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for filename in tqdm(os.listdir(input_folder), desc=f\"Processing {class_folder}\"):\n",
    "            if not filename.endswith('.aedat'):\n",
    "                continue\n",
    "\n",
    "            filepath = os.path.join(input_folder, filename)\n",
    "            output_filepath = os.path.join(output_folder, filename.replace('.aedat', '.pt'))\n",
    "\n",
    "            # Read .aedat file\n",
    "            data = read_aedat_file(filepath)\n",
    "            xs, ys, timestamps = data['xs'], data['ys'], data['timestamps']\n",
    "\n",
    "            # Get range for each axis\n",
    "            x_min, x_max = min(xs), max(xs)\n",
    "            y_min, y_max = min(ys), max(ys)\n",
    "            t_min, t_max = min(timestamps), max(timestamps)\n",
    "\n",
    "            # Initialize voxel grid\n",
    "            voxel_grid = np.zeros(grid_size, dtype=int)\n",
    "\n",
    "            # Map coordinates to voxel grid indices\n",
    "            x_indices = ((np.array(xs) - x_min) / (x_max - x_min) * (grid_size[0] - 1)).astype(int)\n",
    "            y_indices = ((np.array(ys) - y_min) / (y_max - y_min) * (grid_size[1] - 1)).astype(int)\n",
    "            t_indices = ((np.array(timestamps) - t_min) / (t_max - t_min) * (grid_size[2] - 1)).astype(int)\n",
    "\n",
    "            # Count events in each voxel\n",
    "            for x, y, t in zip(x_indices, y_indices, t_indices):\n",
    "                voxel_grid[x, y, t] += 1\n",
    "\n",
    "            # Convert to PyTorch tensor and save\n",
    "            voxel_tensor = torch.tensor(voxel_grid, dtype=torch.float32)\n",
    "            torch.save(voxel_tensor, output_filepath)\n",
    "\n",
    "        print(f\"Category '{class_folder}' processed and saved to {output_folder}\")\n",
    "\n",
    "# Example usage\n",
    "input_base_folder = r\"C:\\\\Users\\\\Lem17\\\\Master Thesis\\\\Data processing\\\\data_aedat2\"\n",
    "output_base_folder = \"./voxel_data_64643\"\n",
    "process_and_save_voxel(input_base_folder, output_base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd02dee-8a36-444a-81fd-d9db5bb81cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
