{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所有参数变量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n",
      "未找到521文件\n"
     ]
    }
   ],
   "source": [
    "import dv_processing as dv\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mmap\n",
    "import aiofiles\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append('./k_search_funciton')  # 添加模块路径\n",
    "import k_search_funciton.file_read as file_read\n",
    "import k_search_funciton.dvs_generate as dvs_generate\n",
    "import k_search_funciton.tag_detector as tag_detector\n",
    "import k_search_funciton.event_filter as event_filter\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "# 设置中文字体\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei'] # 或者 'SimHei', 'Microsoft YaHei' 等\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 避免负号显示为方块\n",
    "except Exception as e:\n",
    "    print(f\"无法设置中文字体: {e}。 图表中的中文可能无法正常显示。\")\n",
    "\n",
    "\n",
    "INPUT_FOLDER = '/mnt/f/raw2event/CIFAR10_DVS_Better/CIFAR10_DVS_Better'  # 替换为你的文件夹路径\n",
    "FILE_SUFFIX = \"200521\"  # 替换为你的文件尾号\n",
    "\n",
    "# 查找匹配的文件\n",
    "try:\n",
    "    files = file_read.find_matching_files(INPUT_FOLDER, FILE_SUFFIX)        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"错误：{str(e)}\")\n",
    "\n",
    "#读取pi数据时用的宽高\n",
    "PI_IMAGE_WEIGHT = 692\n",
    "PI_IMAGE_HEIGHT = 520\n",
    "\n",
    "#生成模拟事件数据时用的k值\n",
    "k_values_raw = [0.00018 * 29250, 20, 0.0001, 1e-7, 5e-9, 0.00001] #用于生成raw模拟事件数据（默认为dvs原始k）\n",
    "k_values_rgb = [0.00018 * 29250, 20, 0.0001, 1e-7, 5e-9, 0.00001] #用于生成rgb模拟事件数据（默认为dvs原始k）\n",
    "\n",
    "#tag检测轨迹用的比例\n",
    "TAG_REF_WIDTH = 287      # AprilTag参考宽度（像素）\n",
    "BARBARA_REF_SIZE = 861   # Barbara参考边长（像素）\n",
    "BARBARA_GAP = 82         # Barbara与tag之间的间隔（像素）\n",
    "margin_ratio = 0.03\n",
    "\n",
    "#线程数量\n",
    "N_WORKERS = 4 \n",
    "\n",
    "#滤取事件数据的批量大小\n",
    "BATCH_SIZE_FOR_EVENT = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#                      数据加载部分                         #\n",
    "############################################################\n",
    "dv_frames, dv_frames_timestamps = file_read.load_frames(files['dv'])\n",
    "dv_events_tensor = file_read.load_events(files['dv'])\n",
    "rgb_frames = file_read.read_rgb_frames(files['rgb_frames'], PI_IMAGE_HEIGHT, PI_IMAGE_WEIGHT)\n",
    "raw_frames = file_read.read_raw_frames(files['raw_frames'], PI_IMAGE_HEIGHT, PI_IMAGE_WEIGHT)\n",
    "pi_timestamps, real_timestamps = file_read.read_metadata(files['metadata'])\n",
    "\n",
    "############################################################\n",
    "#                      生成模拟事件数据                      #\n",
    "############################################################\n",
    "# 单线程生成RGB事件\n",
    "rgb_events_tensor = dvs_generate.generate_events_tensor(\n",
    "pi_timestamps,  # PI相机时间戳\n",
    "rgb_frames,     # RGB帧数据\n",
    "is_rgb=True,    # 标记为RGB数据\n",
    "k_values=k_values_rgb\n",
    ")\n",
    "# 单线程生成RAW事件\n",
    "raw_events_tensor = dvs_generate.generate_events_tensor(\n",
    "pi_timestamps,  # PI相机时间戳\n",
    "raw_frames,     # RAW帧数据\n",
    "is_rgb=False,   # 标记为非RGB (即RAW) 数据\n",
    "k_values=k_values_raw\n",
    ")\n",
    "\n",
    "############################################################\n",
    "#                      时间对齐                            #\n",
    "############################################################\n",
    "# 计算时间偏移量\n",
    "time_offset = file_read.calculate_time_offset(pi_timestamps, real_timestamps)\n",
    "# 调整DV帧时间戳\n",
    "dv_frames_timestamps = dv_frames_timestamps - time_offset\n",
    "# 调整DV事件时间戳\n",
    "dv_events_tensor[:, 0] = dv_events_tensor[:, 0] - time_offset\n",
    "\n",
    "\n",
    "############################################################\n",
    "#                      轨迹数据（并行）                            #\n",
    "############################################################\n",
    "# 构造参数列表\n",
    "margin_ratios = [margin_ratio] * N_WORKERS\n",
    "tag_ref_widths = [TAG_REF_WIDTH] * N_WORKERS\n",
    "barbara_ref_sizes = [BARBARA_REF_SIZE] * N_WORKERS\n",
    "barbara_gaps = [BARBARA_GAP] * N_WORKERS\n",
    "is_raws_rgb = [False] * N_WORKERS\n",
    "is_raws_raw = [True] * N_WORKERS\n",
    "\n",
    "rgb_frame_batches = tag_detector.split_batches(rgb_frames.numpy(), N_WORKERS)\n",
    "raw_frame_batches = tag_detector.split_batches(raw_frames.numpy(), N_WORKERS)\n",
    "ts_batches = tag_detector.split_batches(pi_timestamps, N_WORKERS)\n",
    "\n",
    "dv_frame_batches = tag_detector.split_batches(dv_frames.numpy(), N_WORKERS)\n",
    "dv_ts_batches = tag_detector.split_batches(dv_frames_timestamps, N_WORKERS)\n",
    "\n",
    "#批量得到rgb帧裁剪框信息\n",
    "# 多线程批量处理并显示进度\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    rgb_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            rgb_frame_batches, ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_rgb\n",
    "        ),\n",
    "        total=N_WORKERS\n",
    "    ):\n",
    "        rgb_all_results.append(batch_result)\n",
    "\n",
    "rgb_crops_info = [item for batch in rgb_all_results for item in batch]# 合并所有结果\n",
    "rgb_crops_info.sort(key=lambda x: x[2])  # 按时间戳排序\n",
    "\n",
    "\n",
    "#批量得到raw帧裁剪框信息\n",
    "# 多线程批量处理并显示进度\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    raw_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            raw_frame_batches, ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_raw\n",
    "        ),\n",
    "        total=N_WORKERS\n",
    "    ):\n",
    "        raw_all_results.append(batch_result)\n",
    "\n",
    "raw_crops_info = [item for batch in raw_all_results for item in batch]# 合并所有结果\n",
    "raw_crops_info.sort(key=lambda x: x[2])  #按时间戳排序\n",
    "\n",
    "#批量得到dv帧裁剪框信息\n",
    "# 多线程批量处理并显示进度\n",
    "with ThreadPoolExecutor(max_workers=N_WORKERS) as executor:\n",
    "    dv_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            dv_frame_batches, dv_ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_rgb\n",
    "        ),\n",
    "        total=N_WORKERS\n",
    "    ):\n",
    "        dv_all_results.append(batch_result)\n",
    "\n",
    "dv_crops_info = [item for batch in dv_all_results for item in batch]# 合并所有结果\n",
    "dv_crops_info.sort(key=lambda x: x[2])  # x[2]是timestamp# 按时间戳排序\n",
    "# 第0列: barbara_info - 包含检测到的Barbara标签信息，如多边形顶点、旋转角度、中心点等\n",
    "# 第1列: tag_info - 包含检测到的AprilTag标签信息，如ID、位置等\n",
    "# 第2列: timestamp - 当前帧的时间戳\n",
    "\n",
    "\n",
    "############################################################\n",
    "#                      滤取事件数据                         #\n",
    "############################################################\n",
    "# 假设 box_size 是一个元组 (w, h)\n",
    "def round_up_to_10(x):\n",
    "    return int(math.ceil(x / 10.0) * 10)\n",
    "\n",
    "# 往大取十的整数倍 作为滤取事件数据的最大边长\n",
    "RGB_BOX_SIZE_FOR_EVENT = round_up_to_10(max(rgb_crops_info[0][0]['polygon'].ptp(axis=0)))\n",
    "RAW_BOX_SIZE_FOR_EVENT = round_up_to_10(max(raw_crops_info[0][0]['polygon'].ptp(axis=0)))\n",
    "DV_BOX_SIZE_FOR_EVENT = round_up_to_10(max(dv_crops_info[0][0]['polygon'].ptp(axis=0)))\n",
    "\n",
    "#RGB事件滤取\n",
    "# 使用并行处理函数\n",
    "filtered_events_rgb = event_filter.filter_events_parallel(\n",
    "    events_tensor=rgb_events_tensor,  # 你的事件数据\n",
    "    crops_info=rgb_crops_info,        # 裁剪框信息\n",
    "    target_size=RGB_BOX_SIZE_FOR_EVENT,  # 目标裁剪框大小\n",
    "    transform=True,                    # 是否变换坐标\n",
    "    batch_size=BATCH_SIZE_FOR_EVENT,                # 每批处理的事件数量\n",
    "    n_workers=N_WORKERS                       # 并行进程数\n",
    ")\n",
    "\n",
    "#RAW事件滤取\n",
    "# 使用并行处理函数\n",
    "filtered_events_raw = event_filter.filter_events_parallel(\n",
    "    events_tensor=raw_events_tensor,  # 你的事件数据\n",
    "    crops_info=raw_crops_info,        # 裁剪框信息\n",
    "    target_size=RAW_BOX_SIZE_FOR_EVENT,  # 目标裁剪框大小\n",
    "    transform=True,                    # 是否变换坐标\n",
    "    batch_size=BATCH_SIZE_FOR_EVENT,                # 每批处理的事件数量\n",
    "    n_workers=N_WORKERS                       # 并行进程数\n",
    ")\n",
    "\n",
    "#DV事件滤取\n",
    "# 使用并行处理函数\n",
    "filtered_events_dv = event_filter.filter_events_parallel(\n",
    "    events_tensor=dv_events_tensor,  # 你的事件数据\n",
    "    crops_info=dv_crops_info,        # 裁剪框信息\n",
    "    target_size=DV_BOX_SIZE_FOR_EVENT,  # 目标裁剪框大小\n",
    "    transform=True,                    # 是否变换坐标\n",
    "    batch_size=BATCH_SIZE_FOR_EVENT,                # 每批处理的事件数量\n",
    "    n_workers=N_WORKERS                       # 并行进程数\n",
    ")\n",
    "\n",
    "\n",
    "############################################################\n",
    "#                      结束                              #\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个包含两个子图的图形\n",
    "plt.figure(figsize=(15, 6))  # 调整总图形大小\n",
    "\n",
    "# 第一个子图：RAW帧\n",
    "plt.subplot(1, 2, 1)  # 1行2列的第1个\n",
    "plt.imshow(raw_frames[0].numpy(), cmap='gray')\n",
    "plt.title('RAW Frame 0')\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 第二个子图：RGB帧\n",
    "plt.subplot(1, 2, 2)  # 1行2列的第2个\n",
    "plt.imshow(rgb_frames[0].numpy())\n",
    "plt.title('RGB Frame 0')\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "\n",
    "# 调整子图之间的间距\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间间隔直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k_search_funciton.interval_fit as interval_fit\n",
    "import importlib\n",
    "importlib.reload(interval_fit)\n",
    "\n",
    "\n",
    "num_pixels_rgb, dt_rgb, mu_rgb, sigma_rgb = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "    events=filtered_events_rgb,\n",
    "    min_events_per_pixel=10,         # 例如，每个像素至少需要10个事件\n",
    "    max_dt_us_for_plot=100000,          # 例如，绘图时只看200微秒以下的间隔\n",
    "    plot_bins=100,\n",
    "    type='RGB'\n",
    ")\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "num_pixels_raw, dt_raw, mu_raw, sigma_raw = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "    events=filtered_events_raw,\n",
    "    min_events_per_pixel=10,         # 例如，每个像素至少需要10个事件\n",
    "    max_dt_us_for_plot=100000,          # 例如，绘图时只看200微秒以下的间隔\n",
    "    plot_bins=100,\n",
    "    type='RAW'\n",
    ")\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "\n",
    "num_pixels_dv, dt_dv, mu_dv, sigma_dv = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "    events=filtered_events_dv,\n",
    "    min_events_per_pixel=10,         # 例如，每个像素至少需要10个事件\n",
    "    max_dt_us_for_plot=100000,          # 例如，绘图时只看200微秒以下的间隔\n",
    "    plot_bins=100,\n",
    "    type='DV'\n",
    ")\n",
    "plt.show()  # 显示图形\n",
    "\n",
    "import k_search_funciton.interval_fit as interval_fit\n",
    "import importlib\n",
    "importlib.reload(interval_fit)\n",
    "\n",
    "# 频谱（时间间隔）\n",
    "results = interval_fit.analyze_event_frequency_spectrum(\n",
    "    filtered_events_raw,          # 事件数据\n",
    "    max_freq_hz=100,              # 最大频率限制\n",
    "    bins=50                       # 直方图区间数\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# FFT频谱\n",
    "fft_results = interval_fit.analyze_event_fft_spectrum(\n",
    "    filtered_events_dv,\n",
    "    sampling_rate=1000,   # 采样率 (Hz)\n",
    "    max_freq_hz=100       # 最大频率限制\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filtered_events_dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(interval_fit)\n",
    "\n",
    "# FFT频谱\n",
    "fft_results = interval_fit.analyze_event_fft_spectrum(\n",
    "    filtered_events_dv,\n",
    "    sampling_rate=1000,   # 采样率 (Hz)\n",
    "    max_freq_hz=100       # 最大频率限制\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 裁剪框可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建检测器\n",
    "detector = tag_detector.create_detector()\n",
    "\n",
    "# 处理RGB帧\n",
    "barbara_info_rgb, cropped_rgb, ts_rgb = tag_detector.process_frame(\n",
    "    rgb_frames[0].numpy(), pi_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=False\n",
    ")\n",
    "\n",
    "# 处理RAW帧\n",
    "barbara_info_raw, cropped_raw, ts_raw = tag_detector.process_frame(\n",
    "    raw_frames[0].numpy(), pi_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=True\n",
    ")\n",
    "\n",
    "# 处理DV帧\n",
    "barbara_info_dv, cropped_dv, ts_dv = tag_detector.process_frame(\n",
    "    dv_frames[0].numpy(), dv_frames_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=False\n",
    ")\n",
    "\n",
    "# 在展示图像之前添加以下三行\n",
    "def get_box_size(polygon):\n",
    "    if polygon is None:\n",
    "        return None\n",
    "    width = np.linalg.norm(polygon[1] - polygon[0])  # 底边长度\n",
    "    height = np.linalg.norm(polygon[2] - polygon[1])  # 右边长度\n",
    "    return (width, height)\n",
    "\n",
    "print(f\"RGB框大小: {get_box_size(barbara_info_rgb['polygon'] if barbara_info_rgb else None)}\")\n",
    "print(f\"RAW框大小: {get_box_size(barbara_info_raw['polygon'] if barbara_info_raw else None)}\")\n",
    "print(f\"DV框大小: {get_box_size(barbara_info_dv['polygon'] if barbara_info_dv else None)}\")\n",
    "\n",
    "\n",
    "#展示单帧裁剪效果\n",
    "plt.figure(figsize=(12, 12))\n",
    "# 1. RGB原图\n",
    "plt.subplot(3, 2, 1)\n",
    "frame_img_rgb = rgb_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_rgb)\n",
    "if barbara_info_rgb is not None:\n",
    "    poly = barbara_info_rgb['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('RGB Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 2. RGB裁剪\n",
    "plt.subplot(3, 2, 2)\n",
    "if cropped_rgb is not None:\n",
    "    plt.imshow(cropped_rgb)\n",
    "    plt.title('RGB Cropped Frame')\n",
    "else:\n",
    "    plt.title('RGB Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "# 3. RAW原图\n",
    "plt.subplot(3, 2, 3)\n",
    "frame_img_raw = raw_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_raw, cmap='gray')\n",
    "if barbara_info_raw is not None:\n",
    "    poly = barbara_info_raw['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('RAW Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 4. RAW裁剪\n",
    "plt.subplot(3, 2, 4)\n",
    "if cropped_raw is not None:\n",
    "    plt.imshow(cropped_raw, cmap='gray')\n",
    "    plt.title('RAW Cropped Frame')\n",
    "else:\n",
    "    plt.title('RAW Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "# 5. DV原图\n",
    "plt.subplot(3, 2, 5)\n",
    "frame_img_dv = dv_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_dv, cmap='gray')\n",
    "if barbara_info_dv is not None:\n",
    "    poly = barbara_info_dv['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('DV Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 6. DV裁剪\n",
    "plt.subplot(3, 2, 6)\n",
    "if cropped_dv is not None:\n",
    "    plt.imshow(cropped_dv, cmap='gray')\n",
    "    plt.title('DV Cropped Frame')\n",
    "else:\n",
    "    plt.title('DV Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.15)  # 调小列间距\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 轨迹可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 提取中心点轨迹\n",
    "rgb_centers = np.array([info[0]['center'] for info in rgb_crops_info if info[0] is not None])\n",
    "raw_centers = np.array([info[0]['center'] for info in raw_crops_info if info[0] is not None])\n",
    "dv_centers  = np.array([info[0]['center'] for info in dv_crops_info  if info[0] is not None])\n",
    "\n",
    "\n",
    "# 提取角度\n",
    "rgb_angles = np.array([info[0]['angle'] for info in rgb_crops_info if info[0] is not None])\n",
    "raw_angles = np.array([info[0]['angle'] for info in raw_crops_info if info[0] is not None])\n",
    "dv_angles  = np.array([info[0]['angle'] for info in dv_crops_info  if info[0] is not None])\n",
    "\n",
    "rgb_times = [info[2] for info in rgb_crops_info if info[0] is not None]\n",
    "raw_times = [info[2] for info in raw_crops_info if info[0] is not None]\n",
    "dv_times  = [info[2] for info in dv_crops_info  if info[0] is not None]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 1. 轨迹合并到一个图\n",
    "plt.subplot(2, 1, 1)\n",
    "s =1 # 点的大小\n",
    "lw = 1  # 线宽\n",
    "\n",
    "if len(rgb_centers) > 0:\n",
    "    plt.plot(rgb_centers[:,0], rgb_centers[:,1], '-', color='red', lw=lw, label='RGB')\n",
    "    plt.scatter(rgb_centers[:,0], rgb_centers[:,1], color='red', s=s)\n",
    "\n",
    "if len(raw_centers) > 0:\n",
    "    plt.plot(raw_centers[:,0], raw_centers[:,1], '-', color='green', lw=lw, label='RAW')\n",
    "    plt.scatter(raw_centers[:,0], raw_centers[:,1], color='green', s=s)\n",
    "\n",
    "if len(dv_centers) > 0:\n",
    "    plt.plot(dv_centers[:,0], dv_centers[:,1], '-', color='blue', lw=lw, label='DV')\n",
    "    plt.scatter(dv_centers[:,0], dv_centers[:,1], color='blue', s=s)\n",
    "\n",
    "plt.title('Barbara Center Trajectories')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# 2. 角度随时间合并到一个图\n",
    "plt.subplot(2, 1, 2)\n",
    "s = 4  # 点的大小\n",
    "\n",
    "if len(rgb_angles) > 0:\n",
    "    plt.plot(rgb_times, rgb_angles, '-', color='red', lw=lw, label='RGB')\n",
    "    plt.scatter(rgb_times, rgb_angles, color='red', s=s)\n",
    "\n",
    "if len(raw_angles) > 0:\n",
    "    plt.plot(raw_times, raw_angles, '-', color='green', lw=lw, label='RAW')\n",
    "    plt.scatter(raw_times, raw_angles, color='green', s=s)\n",
    "\n",
    "if len(dv_angles) > 0:\n",
    "    plt.plot(dv_times, dv_angles, '-', color='blue', lw=lw, label='DV')\n",
    "    plt.scatter(dv_times, dv_angles, color='blue', s=s)\n",
    "\n",
    "plt.title('Barbara Angle vs Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Angle (deg)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 滤取事件数据播放可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import datetime \n",
    "\n",
    "def play_filtered_events(events, interval_ms=33, window_size=(230, 230)):\n",
    "    \"\"\"\n",
    "    播放过滤后的事件数据\n",
    "    \n",
    "    参数:\n",
    "    events: 过滤后的事件数据 (PyTorch tensor)\n",
    "    interval_ms: 每帧之间的时间间隔(毫秒)\n",
    "    window_size: 显示窗口大小\n",
    "    \"\"\"\n",
    "    # 创建事件累积器\n",
    "    accumulator = dv.Accumulator(window_size)\n",
    "    \n",
    "    # 设置累积器参数\n",
    "    accumulator.setEventContribution(0.25)\n",
    "    accumulator.setNeutralPotential(0.5)\n",
    "    accumulator.setMinPotential(0.0)\n",
    "    accumulator.setMaxPotential(1.0)\n",
    "    accumulator.setDecayFunction(dv.Accumulator.Decay.LINEAR)\n",
    "    accumulator.setDecayParam(1e-6)\n",
    "    accumulator.setSynchronousDecay(False)\n",
    "    accumulator.setIgnorePolarity(False)\n",
    "    \n",
    "    # 创建预览窗口\n",
    "    cv2.namedWindow(\"Events Preview\", cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # 创建事件切片器\n",
    "    slicer = dv.EventStreamSlicer()\n",
    "    \n",
    "    # 帧计数器\n",
    "    frame_counter = 0\n",
    "    \n",
    "    def accumulate_events(event_slice):\n",
    "        nonlocal frame_counter\n",
    "        \n",
    "        # 将事件切片传递给累积器\n",
    "        accumulator.accept(event_slice)\n",
    "        \n",
    "        # 生成帧\n",
    "        frame = accumulator.generateFrame()\n",
    "        \n",
    "        # 增加帧计数\n",
    "        frame_counter += 1\n",
    "        \n",
    "        # 显示帧\n",
    "        cv2.imshow(\"Events Preview\", frame.image)\n",
    "        cv2.waitKey(2)\n",
    "    \n",
    "    # 设置时间间隔\n",
    "    slicer.doEveryTimeInterval(datetime.timedelta(milliseconds=interval_ms), accumulate_events)\n",
    "    \n",
    "    print(\"开始播放事件数据...\")\n",
    "    \n",
    "    # 获取事件数据\n",
    "    # 我们需要将PyTorch tensor转换为dv库可以处理的事件格式\n",
    "    # 将事件分批处理，每批1000个事件\n",
    "    batch_size = 1000\n",
    "    total_events = len(events)\n",
    "    \n",
    "    for i in range(0, total_events, batch_size):\n",
    "        # 获取当前批次的事件\n",
    "        batch_events = events[i:min(i+batch_size, total_events)]\n",
    "        \n",
    "        # 转换为dv库可以处理的格式\n",
    "        batch = dv.EventStore()\n",
    "        for j in range(len(batch_events)):\n",
    "            event = batch_events[j]\n",
    "            x = int(event[0].item())\n",
    "            y = int(event[1].item())\n",
    "            timestamp = int(event[2].item())\n",
    "            polarity = int(event[3].item())\n",
    "            batch.push_back(dv.Event(x, y, timestamp, polarity))\n",
    "        \n",
    "        # 将事件传递给切片器\n",
    "        slicer.accept(batch)\n",
    "        \n",
    "        # 检查是否按下'q'键退出\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    print(f\"总帧数: {frame_counter}\")\n",
    "    print(\"事件播放完成\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# 播放事件\n",
    "play_filtered_events(filtered_events_dv, 3, (DV_BOX_SIZE_FOR_EVENT, DV_BOX_SIZE_FOR_EVENT))\n",
    "# play_filtered_events(filtered_events_raw, 33, (RAW_BOX_SIZE_FOR_EVENT, RAW_BOX_SIZE_FOR_EVENT))\n",
    "# play_filtered_events(filtered_events_rgb, 33, (RGB_BOX_SIZE_FOR_EVENT, RGB_BOX_SIZE_FOR_EVENT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据EMD黑盒搜索k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#黑盒搜索拟合EMD\n",
    "\n",
    "import csv  # 用于读写CSV文件\n",
    "import os   # 用于处理文件路径和目录\n",
    "import time # 用于记录计算时间\n",
    "import torch # PyTorch库\n",
    "import numpy as np # NumPy库\n",
    "import optuna # Optuna优化库\n",
    "from geomloss import SamplesLoss # 用于计算Sinkhorn距离 (EMD)\n",
    "\n",
    "\n",
    "# 假设以下模块已经可以导入，并且包含了必要的函数\n",
    "import k_search_funciton.dvs_generate as dvs_generate # 自定义DVS事件生成模块\n",
    "import k_search_funciton.event_filter as event_filter   # 自定义事件过滤模块\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 全局配置和预加载数据 (请确保这些变量在运行前已定义)\n",
    "# -------------------------------------------------\n",
    "OUTPUT_PATH = '/mnt/f/raw2event/0513_1305/k_search_grid_output_optuna' # Optuna结果的总输出路径\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True) # 创建总输出路径 (如果不存在)\n",
    "\n",
    "TRIAL_NUM = 3\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 设备配置 (GPU或CPU)\n",
    "if torch.cuda.is_available(): # 检查CUDA是否可用\n",
    "    device = torch.device(\"cuda:0\") # 使用第一个GPU\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\") # 打印GPU名称\n",
    "else:\n",
    "    print(\"Warning: CUDA not available. Running on CPU. EMD might be slow.\") # CUDA不可用警告\n",
    "    device = torch.device(\"cpu\") # 使用CPU\n",
    "\n",
    "# Sinkhorn损失 (EMD) 参数配置\n",
    "emd_blur = 0.01 # EMD计算的模糊参数\n",
    "emd_scaling = 0.9 # EMD计算的缩放参数\n",
    "# 创建Sinkhorn损失函数实例\n",
    "sinkhorn_loss_fn = SamplesLoss(loss=\"sinkhorn\", p=2, blur=emd_blur, scaling=emd_scaling, backend=\"auto\")\n",
    "\n",
    "# CSV文件路径，用于保存所有试验的总结结果\n",
    "summary_csv_path = os.path.join(OUTPUT_PATH, \"optuna_k_search_summary.csv\")\n",
    "\n",
    "# 事件归一化辅助函数\n",
    "def normalize_events(ev_tensor):\n",
    "    \"\"\"将事件数据 (t, x, y) 归一化到 [0, 1] 区间\"\"\"\n",
    "    ev_norm = ev_tensor.clone() # 克隆输入张量以避免修改原始数据\n",
    "    if ev_norm.numel() == 0 or ev_norm.shape[1] < 3: # 如果事件为空或列数不足\n",
    "        return ev_norm # 直接返回\n",
    "    for i in range(3):  # 遍历时间(t), x坐标, y坐标\n",
    "        min_val = ev_norm[:, i].min() # 计算当前列的最小值\n",
    "        max_val = ev_norm[:, i].max() # 计算当前列的最大值\n",
    "        if max_val > min_val: # 如果最大值大于最小值 (避免除以零)\n",
    "            ev_norm[:, i] = (ev_norm[:, i] - min_val) / (max_val - min_val) # 执行归一化\n",
    "        else:\n",
    "            ev_norm[:, i] = 0.0 # 如果所有值相同，则设为0\n",
    "    return ev_norm # 返回归一化后的事件张量\n",
    "\n",
    "# Optuna 的目标函数\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna的目标函数。\n",
    "    它接收一个'trial'对象，使用它建议k参数，\n",
    "    运行事件生成和EMD计算，然后返回EMD距离。\n",
    "    \"\"\"\n",
    "    # 1. Optuna建议k参数值\n",
    "    # 为k1到k6参数建议搜索范围，可以根据经验调整这些范围\n",
    "    k1_val = trial.suggest_float(\"k1\", 0.1, 10.0)       # k1参数，范围0.1到10.0\n",
    "    k2_val = trial.suggest_float(\"k2\", 5.0, 50.0)        # k2参数，范围5.0到50.0\n",
    "    k3_val = trial.suggest_float(\"k3\", 1e-5, 1e-3, log=True) # k3参数，对数尺度，范围1e-5到1e-3\n",
    "    k4_val = trial.suggest_float(\"k4\", 1e-8, 1e-6, log=True) # k4参数，对数尺度，范围1e-8到1e-6\n",
    "    k5_val = trial.suggest_float(\"k5\", 1e-10, 1e-8, log=True)# k5参数，对数尺度，范围1e-10到1e-8\n",
    "    k6_val = trial.suggest_float(\"k6\", 1e-6, 1e-4, log=True) # k6参数，对数尺度，范围1e-6到1e-4\n",
    "    \n",
    "    k_params = [k1_val, k2_val, k3_val, k4_val, k5_val, k6_val] # 将建议的k值组成列表\n",
    "    print(f\"\\nTrial {trial.number}: Testing k_params = {k_params}\") # 打印当前试验编号和k参数\n",
    "\n",
    "    # # 为当前试验创建单独的输出子文件夹 (可选，如果需要保存每组k值的详细结果)\n",
    "    # current_trial_output_path = os.path.join(OUTPUT_PATH, f\"trial_{trial.number}\")\n",
    "    # os.makedirs(current_trial_output_path, exist_ok=True)\n",
    "\n",
    "    # 2. 使用自定义K值生成DVS模拟事件数据 (RAW)\n",
    "    try:\n",
    "        # 生成RAW事件\n",
    "        raw_events_tensor = dvs_generate.generate_events_tensor(\n",
    "            pi_timestamps,  # PI相机时间戳 (需在全局定义)\n",
    "            raw_frames,     # RAW帧数据 (需在全局定义)\n",
    "            is_rgb=False,   # 标记为非RGB (即RAW) 数据\n",
    "            k_values=k_params # 使用当前Optuna建议的k_params\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during RAW event generation: {e}\") # 打印事件生成错误\n",
    "        return float('inf') # 返回一个很大的值，表示此次试验失败\n",
    "\n",
    "    # 3. 事件滤取git a\n",
    "    try:\n",
    "        # RAW事件滤取\n",
    "        filtered_events_raw = event_filter.filter_events_parallel(\n",
    "            events_tensor=raw_events_tensor,                # 输入RAW事件张量\n",
    "            crops_info=raw_crops_info,                      # RAW帧的裁剪信息 (需在全局定义)\n",
    "            target_size=RAW_BOX_SIZE_FOR_EVENT,             # RAW裁剪的目标尺寸 (需在全局定义)\n",
    "            transform=True,                                 # 执行坐标变换\n",
    "            batch_size=BATCH_SIZE_FOR_EVENT,                # 每批处理的事件数量 (需在全局定义)\n",
    "            n_workers=N_WORKERS                   # 并行处理的工作线程数 (需在全局定义)\n",
    "        )\n",
    "\n",
    "        # DV事件滤取 (dv_events_tensor是固定的GT，不依赖k_params重新生成)\n",
    "        filtered_events_dv = event_filter.filter_events_parallel(\n",
    "            events_tensor=dv_events_tensor,                 # 输入预加载的DV事件张量 (需在全局定义)\n",
    "            crops_info=dv_crops_info,                       # DV帧的裁剪信息 (需在全局定义)\n",
    "            target_size=DV_BOX_SIZE_FOR_EVENT,              # DV裁剪的目标尺寸 (需在全局定义)\n",
    "            transform=True,                                 # 执行坐标变换\n",
    "            batch_size=BATCH_SIZE_FOR_EVENT,                # 每批处理的事件数量\n",
    "            n_workers=N_WORKERS                   # 并行处理的工作线程数\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during event filtering: {e}\") # 打印事件过滤错误\n",
    "        return float('inf') # 返回一个很大的值\n",
    "\n",
    "    # 4. 计算 EMD 距离\n",
    "    emd_distance = float('nan')  # 初始化EMD距离为NaN\n",
    "    emd_calc_time = 0.0          # 初始化EMD计算时间\n",
    "\n",
    "    # 检查事件是否为空\n",
    "    if filtered_events_raw is None or filtered_events_raw.shape[0] == 0 or \\\n",
    "       filtered_events_dv is None or filtered_events_dv.shape[0] == 0:\n",
    "        print(\"  RAW or DV events are empty after filtering, cannot calculate EMD.\") # 事件为空的提示\n",
    "        emd_distance = float('inf') # 如果事件为空，EMD设为无穷大以惩罚此试验\n",
    "    else:\n",
    "        # 转换为PyTorch张量并归一化\n",
    "        normalized_raw_events = normalize_events(torch.from_numpy(filtered_events_raw)) # RAW事件归一化\n",
    "        normalized_dv_events = normalize_events(torch.from_numpy(filtered_events_dv))   # DV事件归一化\n",
    "\n",
    "        # 再次检查归一化后事件点云是否有效且至少有3列(t,x,y)\n",
    "        if normalized_raw_events.numel() > 0 and normalized_raw_events.shape[1] >= 3 and \\\n",
    "           normalized_dv_events.numel() > 0 and normalized_dv_events.shape[1] >= 3:\n",
    "\n",
    "            # 取t,x,y三列并转为float32，移动到目标设备\n",
    "            points_raw = normalized_raw_events[:, :3].to(dtype=torch.float32, device=device) # 处理RAW点云\n",
    "            points_dv = normalized_dv_events[:, :3].to(dtype=torch.float32, device=device)   # 处理DV点云\n",
    "\n",
    "            # 确保点数大于0\n",
    "            if points_raw.shape[0] > 0 and points_dv.shape[0] > 0:\n",
    "                print(f\"  Calculating EMD: RAW points {points_raw.shape[0]}, DV points {points_dv.shape[0]}\") # 打印点数信息\n",
    "                start_time = time.time()  # 记录开始时间\n",
    "                try:\n",
    "                    # 构造均匀权重\n",
    "                    w_raw = torch.ones(points_raw.shape[0], device=device) / points_raw.shape[0] # RAW点云权重\n",
    "                    w_dv = torch.ones(points_dv.shape[0], device=device) / points_dv.shape[0]   # DV点云权重\n",
    "                    # 计算Sinkhorn距离\n",
    "                    emd = sinkhorn_loss_fn(w_raw, points_raw, w_dv, points_dv) # 计算EMD\n",
    "                    emd_distance = emd.item()  # 提取标量值\n",
    "                    emd_calc_time = time.time() - start_time  # 计算耗时\n",
    "                    print(f\"  Sinkhorn-EMD: {emd_distance:.6f}, Time: {emd_calc_time:.2f}s\") # 打印EMD结果和耗时\n",
    "                except RuntimeError as e: # 捕获运行时错误\n",
    "                    if \"out of memory\" in str(e).lower(): # 检查是否是显存不足错误\n",
    "                        print(\"  CUDA out of memory during EMD calculation.\") # 打印显存不足信息\n",
    "                        emd_distance = float('inf') # 显存不足时，EMD设为无穷大\n",
    "                    else:\n",
    "                        print(f\"  Runtime error during EMD calculation: {e}\") # 其他运行时错误\n",
    "                        emd_distance = float('inf') # 其他错误时，EMD设为无穷大\n",
    "                except Exception as e: # 捕获其他未知错误\n",
    "                    print(f\"  Unknown error during EMD calculation: {e}\") # 打印未知错误信息\n",
    "                    emd_distance = float('inf') # 未知错误时，EMD设为无穷大\n",
    "            else:\n",
    "                print(\"  RAW or DV points are empty after pre-processing for EMD.\") # 点云为空的提示\n",
    "                emd_distance = float('inf') # 点云为空时，EMD设为无穷大\n",
    "        else:\n",
    "            print(\"  Normalized RAW or DV events are empty or malformed for EMD.\") # 归一化后事件格式错误的提示\n",
    "            emd_distance = float('inf') # 格式错误时，EMD设为无穷大\n",
    "\n",
    "\n",
    "    return emd_distance # 返回EMD距离作为Optuna的优化目标\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 主程序：运行Optuna研究\n",
    "# -------------------------------------------------\n",
    "# 检查关键全局变量是否已定义 (示例性检查，请根据实际情况补充)\n",
    "required_globals = ['pi_timestamps', 'raw_frames', 'dv_events_tensor', 'raw_crops_info', 'dv_crops_info',\n",
    "                    'RAW_BOX_SIZE_FOR_EVENT', 'DV_BOX_SIZE_FOR_EVENT', 'BATCH_SIZE_FOR_EVENT', 'N_WORKERS_FOR_EVENT']\n",
    "for var_name in required_globals:\n",
    "    if var_name not in globals():\n",
    "        print(f\"错误: 全局变量 '{var_name}' 未定义。请在运行Optuna优化前加载它。\")\n",
    "        exit()\n",
    "\n",
    "print(f\"Optuna study K值搜索开始。结果将保存到: {OUTPUT_PATH}\") # 打印开始信息\n",
    "print(f\"所有试验的总结将记录在: {summary_csv_path}\") # 打印总结文件路径\n",
    "\n",
    "# 创建Optuna研究对象，目标是最小化objective函数的返回值 (EMD距离)\n",
    "# 可以为 study_name 和 storage 指定数据库URL，以便持久化和恢复研究\n",
    "# 例如 storage=\"sqlite:///example.db\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"dvs_k_param_optimization\",\n",
    "    storage=\"sqlite:///optuna_k_search.db\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# timeout参数可以用来限制总优化时间（秒）\n",
    "study.optimize(objective, n_trials=TRIAL_NUM, timeout=None) # 运行100次试验\n",
    "study.trials_dataframe().to_csv(summary_csv_path, index=False)\n",
    "print(f\"\\n所有试验的详细结果已保存到: {summary_csv_path}\")\n",
    "\n",
    "\n",
    "# 优化结束后打印研究结果\n",
    "print(\"\\nOptuna K值搜索完成。\") # 打印完成信息\n",
    "print(f\"最佳试验 Trial {study.best_trial.number}:\") # 打印最佳试验编号\n",
    "print(f\"  最佳 EMD 值: {study.best_value:.6f}\") # 打印最佳EMD值\n",
    "print(\"  最佳参数 K:\") # 打印最佳参数\n",
    "for key, value in study.best_params.items(): # 遍历最佳参数\n",
    "    print(f\"    {key}: {value:.7g}\") # 打印每个最佳参数值\n",
    "\n",
    "print(f\"\\n所有试验的详细结果已保存到: {summary_csv_path}\") # 提示结果保存路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据u和sigma黑盒搜索k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 黑盒搜索拟合u和sigma (使用Optuna)\n",
    "# 确保运行了之前的 1, 2, 3, 4号代码块以加载必要数据和函数\n",
    "\n",
    "import csv                          # CSV操作 (Optuna后可移除部分手动CSV操作)\n",
    "import os                           # 操作系统功能，如路径处理\n",
    "import numpy as np                  # Numpy库，用于数值计算\n",
    "import matplotlib.pyplot as plt     # Matplotlib库，用于绘图\n",
    "import optuna                       # Optuna优化库\n",
    "\n",
    "# 确保以下自定义模块已加载且路径正确\n",
    "import k_search_funciton.event_filter as event_filter\n",
    "import k_search_funciton.dvs_generate as dvs_generate # 假设此模块存在\n",
    "import k_search_funciton.interval_fit as interval_fit\n",
    "import importlib\n",
    "importlib.reload(event_filter)\n",
    "importlib.reload(dvs_generate) # 如果有修改，重新加载\n",
    "importlib.reload(interval_fit) # 如果有修改，重新加载\n",
    "import math\n",
    "\n",
    "# 假设 box_size 是一个元组 (w, h)\n",
    "def round_up_to_10(x):\n",
    "    return int(math.ceil(x / 10.0) * 10)\n",
    "\n",
    "# 取每个框的最大边长\n",
    "rgb_box_size = max(barbara_info_rgb['polygon'].ptp(axis=0))\n",
    "raw_box_size = max(barbara_info_raw['polygon'].ptp(axis=0))\n",
    "dv_box_size = max(barbara_info_dv['polygon'].ptp(axis=0))\n",
    "\n",
    "# 往大取十的整数倍\n",
    "RGB_BOX_SIZE_FOR_EVENT = round_up_to_10(rgb_box_size)\n",
    "RAW_BOX_SIZE_FOR_EVENT = round_up_to_10(raw_box_size)\n",
    "DV_BOX_SIZE_FOR_EVENT = round_up_to_10(dv_box_size)\n",
    "BATCH_SIZE_FOR_EVENT = 100000\n",
    "N_WORKERS_FOR_EVENT = 4\n",
    "\n",
    "\n",
    "TRIAL_NUM = 3\n",
    "\n",
    "# --- 配置和预加载数据 (应从之前的代码块继承) ---\n",
    "OUTPUT_PATH = '/mnt/f/raw2event/0513_1305/k_search_optuna_output' # Optuna结果的新输出路径\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True) # 创建输出路径\n",
    "\n",
    "# 初始K值 (作为Optuna搜索的中心参考)\n",
    "k1_initial = 5.0\n",
    "k2_initial = 20.0\n",
    "k3_initial = 0.0001\n",
    "k4_initial = 1e-7\n",
    "k5_initial = 5e-9\n",
    "k6_initial = 1e-5\n",
    "\n",
    "# --- DV事件处理 (只需执行一次，在Optuna优化外部) ---\n",
    "print(\"正在处理DV事件 (仅一次)...\")\n",
    "# DV事件滤取\n",
    "filtered_events_dv = event_filter.filter_events_parallel(\n",
    "    events_tensor=dv_events_tensor,           # 输入预加载的DV事件张量\n",
    "    crops_info=dv_crops_info,                 # DV帧的裁剪信息\n",
    "    target_size=DV_BOX_SIZE_FOR_EVENT,        # DV裁剪的目标尺寸\n",
    "    transform=True,                           # 执行坐标变换\n",
    "    batch_size=BATCH_SIZE_FOR_EVENT,          # 每批处理的事件数量\n",
    "    n_workers=N_WORKERS_FOR_EVENT             # 并行处理的工作线程数\n",
    ")\n",
    "\n",
    "# 对滤取后的DV事件进行间隔拟合\n",
    "num_pixels_dv_global, dt_dv_global, mu_dv_global, sigma_dv_global = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "    events=filtered_events_dv,          # 输入滤取后的DV事件\n",
    "    min_events_per_pixel=10,            # 每个像素最少事件数\n",
    "    max_dt_us_for_plot=100000,          # 绘图显示的最大时间间隔\n",
    "    plot_bins=100,                      # 直方图的bins数量\n",
    "    type='DV_Global'                    # 数据类型标记\n",
    ")\n",
    "# 保存DV拟合的图像和数据 (仅一次)\n",
    "if mu_dv_global is not np.nan : # 检查拟合是否成功\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'interval_fit_dv_global.png'))\n",
    "    plt.close()\n",
    "    np.savez(os.path.join(OUTPUT_PATH, 'interval_fit_dv_global.npz'),\n",
    "             num_pixels=num_pixels_dv_global, dt=dt_dv_global, mu=mu_dv_global, sigma=sigma_dv_global)\n",
    "    print(f\"DV事件拟合完成: mu_dv={mu_dv_global:.4f}, sigma_dv={sigma_dv_global:.4f}\")\n",
    "else:\n",
    "    print(\"错误：DV事件拟合失败，无法进行优化。请检查DV数据和拟合函数。\")\n",
    "    # 根据情况决定是否退出 exit()\n",
    "\n",
    "# --- Optuna 目标函数定义 ---\n",
    "def objective(trial):\n",
    "    global mu_dv_global, sigma_dv_global # 确保能访问全局的DV拟合结果\n",
    "\n",
    "    # 1. Optuna建议K参数值 (对数尺度搜索)\n",
    "    # 调整搜索范围因子，例如k_initial/factor 到 k_initial*factor\n",
    "    # 对较小值使用更大的因子范围，如100x；对较大值使用较小因子，如10x\n",
    "    k1_val = trial.suggest_float(\"k1\", k1_initial / 10, k1_initial * 10, log=True)\n",
    "    k2_val = trial.suggest_float(\"k2\", k2_initial / 10, k2_initial * 10, log=True)\n",
    "    k3_val = trial.suggest_float(\"k3\", k3_initial / 100, k3_initial * 100, log=True)\n",
    "    k4_val = trial.suggest_float(\"k4\", k4_initial / 100, k4_initial * 100, log=True)\n",
    "    k5_val = trial.suggest_float(\"k5\", k5_initial / 100, k5_initial * 100, log=True)\n",
    "    k6_val = trial.suggest_float(\"k6\", k6_initial / 100, k6_initial * 100, log=True)\n",
    "    \n",
    "    k_params = [k1_val, k2_val, k3_val, k4_val, k5_val, k6_val]\n",
    "    print(f\"\\nTrial {trial.number}: 测试 K参数 = {k_params}\")\n",
    "\n",
    "    # --- 2. 使用建议的K值生成DVS模拟事件数据 ---\n",
    "    try:\n",
    "        raw_events_tensor = dvs_generate.generate_events_tensor(\n",
    "            pi_timestamps,  # PI相机时间戳 (需全局可用)\n",
    "            raw_frames,     # RAW帧数据 (需全局可用)\n",
    "            is_rgb=False,   # 标记为非RGB (即RAW) 数据\n",
    "            k_values=k_params\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  错误：RAW事件生成失败: {e}\")\n",
    "        return float('inf') # 事件生成失败，返回一个很大的损失值\n",
    "\n",
    "    # --- 3. 事件滤取 (RAW) ---\n",
    "    try:\n",
    "        filtered_events_raw = event_filter.filter_events_parallel(\n",
    "            events_tensor=raw_events_tensor,\n",
    "            crops_info=raw_crops_info,             # RAW帧的裁剪信息 (需全局可用)\n",
    "            target_size=RAW_BOX_SIZE_FOR_EVENT,    # RAW裁剪的目标尺寸 (需全局可用)\n",
    "            transform=True,\n",
    "            batch_size=BATCH_SIZE_FOR_EVENT,       # (需全局可用)\n",
    "            n_workers=N_WORKERS                   # (需全局可用)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  错误：RAW事件滤波失败: {e}\")\n",
    "        return float('inf') # 事件滤波失败\n",
    "\n",
    "    # --- 4. 间隔拟合 (RAW) ---\n",
    "    # 注意：analyze_per_pixel_event_intervals_combined 内部有绘图，Optuna大量迭代时应考虑关闭或修改\n",
    "    # 为避免过多图像文件，这里的plt.savefig和plt.close可以注释掉，或只为最佳trial保存\n",
    "    num_pixels_raw, dt_raw, mu_raw, sigma_raw = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "        events=filtered_events_raw,\n",
    "        min_events_per_pixel=10,\n",
    "        max_dt_us_for_plot=100000, # 在objective中可以设为更小的值或不绘图以加速\n",
    "        plot_bins=100,\n",
    "        type=f'RAW_Trial_{trial.number}' # 区分不同试验的类型名\n",
    "    )\n",
    "    plt.close() # 关闭interval_fit内部的绘图，避免显示过多窗口\n",
    "\n",
    "    # 检查拟合结果是否有效\n",
    "    if mu_raw is np.nan or sigma_raw is np.nan or mu_dv_global is np.nan or sigma_dv_global is np.nan:\n",
    "        print(f\"  警告：拟合参数包含NaN (mu_raw={mu_raw}, sigma_raw={sigma_raw})。此试验将被惩罚。\")\n",
    "        return float('inf') # 拟合失败或DV基准无效，返回很大的损失值\n",
    "\n",
    "    print(f\"  RAW拟合结果: mu_raw={mu_raw:.4f}, sigma_raw={sigma_raw:.4f}\")\n",
    "    \n",
    "    # --- 5. 计算损失函数 ---\n",
    "    # 目标是让mu_raw接近mu_dv, sigma_raw接近sigma_dv\n",
    "    # 可以使用绝对差之和，或归一化的平方差之和等\n",
    "    # 为避免除零，对分母加一个小数\n",
    "    loss_mu = (abs(mu_raw - mu_dv_global)) / (abs(mu_dv_global) + 1e-9) \n",
    "    loss_sigma = (abs(sigma_raw - sigma_dv_global)) / (abs(sigma_dv_global) + 1e-9)\n",
    "    \n",
    "    # 可以给mu和sigma的匹配赋予不同权重，这里简单相加\n",
    "    total_loss = loss_mu + loss_sigma \n",
    "    \n",
    "    print(f\"  损失值: {total_loss:.6f} (mu_loss={loss_mu:.4f}, sigma_loss={loss_sigma:.4f})\")\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# --- Optuna 研究设置与执行 ---\n",
    "if mu_dv_global is not np.nan and sigma_dv_global is not np.nan: # 确保DV基准有效\n",
    "    print(\"\\n开始Optuna K参数优化搜索...\")\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",                     # 优化目标是最小化损失函数\n",
    "        study_name=\"dvs_k_params_optimization_6k\", # 研究名称\n",
    "        storage=f\"sqlite:///{os.path.join(OUTPUT_PATH, 'optuna_6k_study.db')}\", # SQLite数据库保存研究结果\n",
    "        load_if_exists=True                       # 如果数据库已存在，则加载之前的研究\n",
    "    )\n",
    "\n",
    "    # 设置试验次数，例如100次\n",
    "    study.optimize(objective, n_trials=TRIAL_NUM, timeout=None) # timeout参数可以用来限制总优化时间（秒）\n",
    "\n",
    "    # --- 输出优化结果 ---\n",
    "    print(\"\\nOptuna K参数优化完成。\")\n",
    "    print(f\"最佳试验 Trial {study.best_trial.number}:\")\n",
    "    print(f\"  最佳损失值: {study.best_value:.6f}\")\n",
    "    print(\"  最佳参数 K:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"    {key}: {value:.7g}\") # 使用科学计数法或适当格式打印\n",
    "\n",
    "    # 你可以在这里添加代码，使用最佳参数重新运行一次完整的流程，并保存所有相关的输出文件(事件、拟合图等)\n",
    "    # 例如:\n",
    "    # best_k_params = [study.best_params[f'k{i+1}'] for i in range(6)]\n",
    "    # ... 然后运行生成、滤波、拟合，并保存到特定文件夹 ...\n",
    "\n",
    "    # 将所有试验结果保存到CSV文件\n",
    "    try:\n",
    "        trials_df = study.trials_dataframe()\n",
    "        trials_df.to_csv(os.path.join(OUTPUT_PATH, \"optuna_6k_trials_summary.csv\"), index=False)\n",
    "        print(f\"\\n所有试验的详细结果已保存到: {os.path.join(OUTPUT_PATH, 'optuna_6k_trials_summary.csv')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存Optuna试验总结到CSV时出错: {e}\")\n",
    "else:\n",
    "    print(\"由于DV事件拟合失败，Optuna优化未启动。\")\n",
    "\n",
    "print(\"\\n--- 脚本执行完毕 ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
