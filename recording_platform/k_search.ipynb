{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enter the address, variable, and import the necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dv_processing as dv\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import mmap\n",
    "import aiofiles\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append('./k_search_funciton')  # Add module path\n",
    "import k_search_funciton.file_read as file_read\n",
    "\n",
    "# Set Chinese font\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei'] # or 'SimHei', 'Microsoft YaHei', etc.\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # Avoid negative signs displaying as squares\n",
    "except Exception as e:\n",
    "    print(f\"Unable to set Chinese font: {e}. Chinese characters in charts may not display correctly.\")\n",
    "\n",
    "\n",
    "INPUT_FOLDER = \"/mnt/f/raw2event/0511_1620/\"  # Replace with your folder path\n",
    "FILE_SUFFIX = \"172631\"  # Replace with your file suffix\n",
    "\n",
    "try:\n",
    "    # Find matching files\n",
    "    files = file_read.find_matching_files(INPUT_FOLDER, FILE_SUFFIX)        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "\n",
    "\n",
    "PI_IMAGE_WEIGHT = 692  # Width of the image\n",
    "PI_IMAGE_HEIGHT = 520  # Height of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "\n",
    "# Load frame data\n",
    "dv_frames, dv_frames_timestamps = file_read.load_frames(files['dv'])\n",
    "\n",
    "print(f\"DV frame data shape: {dv_frames.shape}\")\n",
    "print(f\"Number of DV frame timestamps: {len(dv_frames_timestamps)}\")\n",
    "\n",
    "# Load event data\n",
    "dv_events_tensor = file_read.load_events(files['dv'])\n",
    "print(f\"DV event data shape: {dv_events_tensor.shape}\")\n",
    "print(f\"DV event timestamp range: [{dv_events_tensor[:, 0].min()}, {dv_events_tensor[:, 0].max()}]\")\n",
    "\n",
    "# Read PI camera data (asynchronous)\n",
    "# pi_timestamps, real_timestamps, raw_frames, rgb_frames = await file_read.read_pi_data_async(\n",
    "#     METADATA_INPUT,\n",
    "#     RAW_FRAMES_INPUT,\n",
    "#     RGB_FRAMES_INPUT,\n",
    "#     PI_IMAGE_HEIGHT,\n",
    "#     PI_IMAGE_WEIGHT\n",
    "# )\n",
    "\n",
    "rgb_frames = file_read.read_rgb_frames(files['rgb_frames'], PI_IMAGE_HEIGHT, PI_IMAGE_WEIGHT)\n",
    "raw_frames = file_read.read_raw_frames(files['raw_frames'], PI_IMAGE_HEIGHT, PI_IMAGE_WEIGHT)\n",
    "pi_timestamps, real_timestamps = file_read.read_metadata(files['metadata'])\n",
    "\n",
    "# Print timestamps\n",
    "print(f\"Number of timestamps: {len(pi_timestamps)}\")\n",
    "print(f\"Timestamp range: {pi_timestamps[0]:.2f} - {pi_timestamps[-1]:.2f}\")\n",
    "print(f\"Number of real timestamps: {len(real_timestamps)}\")\n",
    "print(f\"Real timestamp range: {real_timestamps[0]:.2f} - {real_timestamps[-1]:.2f}\")\n",
    "\n",
    "# Create a figure with two subplots\n",
    "plt.figure(figsize=(15, 6))  # Adjust total figure size\n",
    "\n",
    "# First subplot: RAW frame\n",
    "plt.subplot(1, 2, 1)  # 1st of 1 row, 2 columns\n",
    "plt.imshow(raw_frames[0].numpy(), cmap='gray')\n",
    "plt.title('RAW Frame 0')\n",
    "plt.axis('off')  # Turn off axis\n",
    "\n",
    "# Second subplot: RGB frame\n",
    "plt.subplot(1, 2, 2)  # 2nd of 1 row, 2 columns\n",
    "plt.imshow(rgb_frames[0].numpy())\n",
    "plt.title('RGB Frame 0')\n",
    "plt.axis('off')  # Turn off axis\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Timestamp alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time offset\n",
    "time_offset = file_read.calculate_time_offset(pi_timestamps, real_timestamps)\n",
    "print(f\"Time offset: {time_offset} microseconds\")\n",
    "\n",
    "# Adjust DV frame timestamps\n",
    "dv_frames_timestamps = dv_frames_timestamps - time_offset\n",
    "\n",
    "# Adjust DV event timestamps\n",
    "dv_events_tensor[:, 0] = dv_events_tensor[:, 0] - time_offset\n",
    "\n",
    "# Print adjusted time ranges\n",
    "print(f\"Adjusted DV frame timestamp range: [{dv_frames_timestamps[0]}, {dv_frames_timestamps[-1]}]\")\n",
    "print(f\"Adjusted DV event timestamp range: [{dv_events_tensor[:, 0].min()}, {dv_events_tensor[:, 0].max()}]\")\n",
    "print(f\"PI timestamp range: {pi_timestamps[0]:.2f} - {pi_timestamps[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract frame information based on frame data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k_search_funciton.tag_detector as tag_detector\n",
    "import importlib\n",
    "importlib.reload(tag_detector)\n",
    "import cv2\n",
    "TAG_REF_WIDTH = 287      # AprilTag reference width (pixels)\n",
    "BARBARA_REF_SIZE = 861   # Barbara reference side length (pixels)\n",
    "BARBARA_GAP = 82         # Gap between Barbara and tag (pixels)\n",
    "margin_ratio = 0.03\n",
    "\n",
    "# Create detector\n",
    "detector = tag_detector.create_detector()\n",
    "\n",
    "# Process RGB frame\n",
    "barbara_info_rgb, cropped_rgb, ts_rgb = tag_detector.process_frame(\n",
    "    rgb_frames[0].numpy(), pi_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=False\n",
    ")\n",
    "\n",
    "# Process RAW frame\n",
    "barbara_info_raw, cropped_raw, ts_raw = tag_detector.process_frame(\n",
    "    raw_frames[0].numpy(), pi_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=True\n",
    ")\n",
    "\n",
    "# Process DV frame\n",
    "barbara_info_dv, cropped_dv, ts_dv = tag_detector.process_frame(\n",
    "    dv_frames[0].numpy(), dv_frames_timestamps[0], detector, \n",
    "    margin_ratio=margin_ratio, \n",
    "    tag_ref_width=TAG_REF_WIDTH, \n",
    "    barbara_ref_size=BARBARA_REF_SIZE, \n",
    "    barbara_gap=BARBARA_GAP,\n",
    "    is_raw=False\n",
    ")\n",
    "\n",
    "# Add these three lines before displaying images\n",
    "def get_box_size(polygon):\n",
    "    if polygon is None:\n",
    "        return None\n",
    "    width = np.linalg.norm(polygon[1] - polygon[0])  # Bottom edge length\n",
    "    height = np.linalg.norm(polygon[2] - polygon[1])  # Right edge length\n",
    "    return (width, height)\n",
    "\n",
    "print(f\"RGB box size: {get_box_size(barbara_info_rgb['polygon'] if barbara_info_rgb else None)}\")\n",
    "print(f\"RAW box size: {get_box_size(barbara_info_raw['polygon'] if barbara_info_raw else None)}\")\n",
    "print(f\"DV box size: {get_box_size(barbara_info_dv['polygon'] if barbara_info_dv else None)}\")\n",
    "\n",
    "# Display single frame cropping results\n",
    "plt.figure(figsize=(12, 12))\n",
    "# 1. RGB original image\n",
    "plt.subplot(3, 2, 1)\n",
    "frame_img_rgb = rgb_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_rgb)\n",
    "if barbara_info_rgb is not None:\n",
    "    poly = barbara_info_rgb['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('RGB Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 2. RGB cropped image\n",
    "plt.subplot(3, 2, 2)\n",
    "if cropped_rgb is not None:\n",
    "    plt.imshow(cropped_rgb)\n",
    "    plt.title('RGB Cropped Frame')\n",
    "else:\n",
    "    plt.title('RGB Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "# 3. RAW original image\n",
    "plt.subplot(3, 2, 3)\n",
    "frame_img_raw = raw_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_raw, cmap='gray')\n",
    "if barbara_info_raw is not None:\n",
    "    poly = barbara_info_raw['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('RAW Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 4. RAW cropped image\n",
    "plt.subplot(3, 2, 4)\n",
    "if cropped_raw is not None:\n",
    "    plt.imshow(cropped_raw, cmap='gray')\n",
    "    plt.title('RAW Cropped Frame')\n",
    "else:\n",
    "    plt.title('RAW Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "# 5. DV original image\n",
    "plt.subplot(3, 2, 5)\n",
    "frame_img_dv = dv_frames[0].numpy().copy()\n",
    "plt.imshow(frame_img_dv, cmap='gray')\n",
    "if barbara_info_dv is not None:\n",
    "    poly = barbara_info_dv['polygon']\n",
    "    x, y = poly[:,0], poly[:,1]\n",
    "    plt.plot(x, y, '-', color='lime', linewidth=4)\n",
    "    plt.plot([x[-1], x[0]], [y[-1], y[0]], '-', color='lime', linewidth=4)\n",
    "plt.title('DV Frame with Barbara Region')\n",
    "plt.axis('off')\n",
    "\n",
    "# 6. DV cropped image\n",
    "plt.subplot(3, 2, 6)\n",
    "if cropped_dv is not None:\n",
    "    plt.imshow(cropped_dv, cmap='gray')\n",
    "    plt.title('DV Cropped Frame')\n",
    "else:\n",
    "    plt.title('DV Cropped Frame (None)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.15)  # Reduce column spacing\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import k_search_funciton.tag_detector as tag_detector\n",
    "import importlib\n",
    "importlib.reload(tag_detector)\n",
    "\n",
    "n_workers = 4  # Number of threads\n",
    "# Construct parameter lists\n",
    "margin_ratios = [margin_ratio] * n_workers\n",
    "tag_ref_widths = [TAG_REF_WIDTH] * n_workers\n",
    "barbara_ref_sizes = [BARBARA_REF_SIZE] * n_workers\n",
    "barbara_gaps = [BARBARA_GAP] * n_workers\n",
    "is_raws_rgb = [False] * n_workers\n",
    "is_raws_raw = [True] * n_workers\n",
    "\n",
    "rgb_frame_batches = tag_detector.split_batches(rgb_frames.numpy(), n_workers)\n",
    "raw_frame_batches = tag_detector.split_batches(raw_frames.numpy(), n_workers)\n",
    "ts_batches = tag_detector.split_batches(pi_timestamps, n_workers)\n",
    "\n",
    "dv_frame_batches = tag_detector.split_batches(dv_frames.numpy(), n_workers)\n",
    "dv_ts_batches = tag_detector.split_batches(dv_frames_timestamps, n_workers)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Batch process RGB frames to get cropping box information\n",
    "# Multi-threaded batch processing with progress display\n",
    "with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "    rgb_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            rgb_frame_batches, ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_rgb\n",
    "        ),\n",
    "        total=n_workers\n",
    "    ):\n",
    "        rgb_all_results.append(batch_result)\n",
    "\n",
    "# Merge all results\n",
    "rgb_crops_info = [item for batch in rgb_all_results for item in batch]\n",
    "\n",
    "# Sort by timestamp\n",
    "rgb_crops_info.sort(key=lambda x: x[2])  # x[2] is timestamp\n",
    "\n",
    "# Batch process RAW frames to get cropping box information\n",
    "# Multi-threaded batch processing with progress display\n",
    "with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "    raw_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            raw_frame_batches, ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_raw\n",
    "        ),\n",
    "        total=n_workers\n",
    "    ):\n",
    "        raw_all_results.append(batch_result)\n",
    "\n",
    "# Merge all results\n",
    "raw_crops_info = [item for batch in raw_all_results for item in batch]\n",
    "\n",
    "# Sort by timestamp\n",
    "raw_crops_info.sort(key=lambda x: x[2])  # x[2] is timestamp\n",
    "\n",
    "# Batch process DV frames to get cropping box information\n",
    "# Multi-threaded batch processing with progress display\n",
    "with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "    dv_all_results = []\n",
    "    for batch_result in tqdm(\n",
    "        executor.map(\n",
    "            tag_detector.process_batch,\n",
    "            dv_frame_batches, dv_ts_batches,\n",
    "            margin_ratios, tag_ref_widths, barbara_ref_sizes, barbara_gaps, is_raws_rgb\n",
    "        ),\n",
    "        total=n_workers\n",
    "    ):\n",
    "        dv_all_results.append(batch_result)\n",
    "\n",
    "# Merge all results\n",
    "dv_crops_info = [item for batch in dv_all_results for item in batch]\n",
    "\n",
    "# Sort by timestamp\n",
    "dv_crops_info.sort(key=lambda x: x[2])  # x[2] is timestamp\n",
    "\n",
    "# Column 0: barbara_info - Contains detected Barbara tag information, such as polygon vertices, rotation angle, center point, etc.\n",
    "# Column 1: tag_info - Contains detected AprilTag information, such as ID, position, etc.\n",
    "# Column 2: timestamp - Timestamp of the current frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Extract center point trajectories\n",
    "rgb_centers = np.array([info[0]['center'] for info in rgb_crops_info if info[0] is not None])\n",
    "raw_centers = np.array([info[0]['center'] for info in raw_crops_info if info[0] is not None])\n",
    "dv_centers  = np.array([info[0]['center'] for info in dv_crops_info  if info[0] is not None])\n",
    "\n",
    "# Extract angles\n",
    "rgb_angles = np.array([info[0]['angle'] for info in rgb_crops_info if info[0] is not None])\n",
    "raw_angles = np.array([info[0]['angle'] for info in raw_crops_info if info[0] is not None])\n",
    "dv_angles  = np.array([info[0]['angle'] for info in dv_crops_info  if info[0] is not None])\n",
    "\n",
    "rgb_times = [info[2] for info in rgb_crops_info if info[0] is not None]\n",
    "raw_times = [info[2] for info in raw_crops_info if info[0] is not None]\n",
    "dv_times  = [info[2] for info in dv_crops_info  if info[0] is not None]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# 1. Combine trajectories in one plot\n",
    "plt.subplot(2, 1, 1)\n",
    "s = 1  # Point size\n",
    "lw = 1  # Line width\n",
    "\n",
    "if len(rgb_centers) > 0:\n",
    "    plt.plot(rgb_centers[:,0], rgb_centers[:,1], '-', color='red', lw=lw, label='RGB')\n",
    "    plt.scatter(rgb_centers[:,0], rgb_centers[:,1], color='red', s=s)\n",
    "\n",
    "if len(raw_centers) > 0:\n",
    "    plt.plot(raw_centers[:,0], raw_centers[:,1], '-', color='green', lw=lw, label='RAW')\n",
    "    plt.scatter(raw_centers[:,0], raw_centers[:,1], color='green', s=s)\n",
    "\n",
    "if len(dv_centers) > 0:\n",
    "    plt.plot(dv_centers[:,0], dv_centers[:,1], '-', color='blue', lw=lw, label='DV')\n",
    "    plt.scatter(dv_centers[:,0], dv_centers[:,1], color='blue', s=s)\n",
    "\n",
    "plt.title('Barbara Center Trajectories')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# 2. Combine angles over time in one plot\n",
    "plt.subplot(2, 1, 2)\n",
    "s = 4  # Point size\n",
    "\n",
    "if len(rgb_angles) > 0:\n",
    "    plt.plot(rgb_times, rgb_angles, '-', color='red', lw=lw, label='RGB')\n",
    "    plt.scatter(rgb_times, rgb_angles, color='red', s=s)\n",
    "\n",
    "if len(raw_angles) > 0:\n",
    "    plt.plot(raw_times, raw_angles, '-', color='green', lw=lw, label='RAW')\n",
    "    plt.scatter(raw_times, raw_angles, color='green', s=s)\n",
    "\n",
    "if len(dv_angles) > 0:\n",
    "    plt.plot(dv_times, dv_angles, '-', color='blue', lw=lw, label='DV')\n",
    "    plt.scatter(dv_times, dv_angles, color='blue', s=s)\n",
    "\n",
    "plt.title('Barbara Angle vs Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Angle (deg)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter event data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k_search_funciton.event_filter as event_filter\n",
    "import importlib\n",
    "importlib.reload(event_filter)\n",
    "import math\n",
    "\n",
    "# Assuming box_size is a tuple (w, h)\n",
    "def round_up_to_10(x):\n",
    "    return int(math.ceil(x / 10.0) * 10)\n",
    "\n",
    "# Get the maximum side length of each box\n",
    "rgb_box_size = max(barbara_info_rgb['polygon'].ptp(axis=0))\n",
    "raw_box_size = max(barbara_info_raw['polygon'].ptp(axis=0))\n",
    "dv_box_size = max(barbara_info_dv['polygon'].ptp(axis=0))\n",
    "\n",
    "# Round up to the nearest multiple of 10\n",
    "RGB_BOX_SIZE_FOR_EVENT = round_up_to_10(rgb_box_size)\n",
    "RAW_BOX_SIZE_FOR_EVENT = round_up_to_10(raw_box_size)\n",
    "DV_BOX_SIZE_FOR_EVENT = round_up_to_10(dv_box_size)\n",
    "BATCH_SIZE_FOR_EVENT = 100000\n",
    "N_WORKERS_FOR_EVENT = 4\n",
    "\n",
    "# DV event filtering\n",
    "# Use parallel processing function\n",
    "filtered_events_dv = event_filter.filter_events_parallel(\n",
    "    events_tensor=dv_events_tensor,  # Your event data\n",
    "    crops_info=dv_crops_info,        # Cropping box information\n",
    "    target_size=DV_BOX_SIZE_FOR_EVENT,  # Target cropping box size\n",
    "    transform=True,                    # Whether to transform coordinates\n",
    "    batch_size=BATCH_SIZE_FOR_EVENT,                # Number of events per batch\n",
    "    n_workers=N_WORKERS_FOR_EVENT                       # Number of parallel processes\n",
    ")\n",
    "\n",
    "# Check results\n",
    "print(f\"Number of filtered DV events: {len(filtered_events_dv)}\")\n",
    "print(f\"DV event timestamp range: [{filtered_events_dv[0, 0]}, {filtered_events_dv[-1, 0]}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Event Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import datetime \n",
    "\n",
    "def play_filtered_events(events, interval_ms=33, window_size=(230, 230)):\n",
    "    \"\"\"\n",
    "    Play filtered event data\n",
    "    \n",
    "    Parameters:\n",
    "    events: Filtered event data (PyTorch tensor)\n",
    "    interval_ms: Time interval between frames (milliseconds)\n",
    "    window_size: Display window size\n",
    "    \"\"\"\n",
    "    # Create event accumulator\n",
    "    accumulator = dv.Accumulator(window_size)\n",
    "    \n",
    "    # Set accumulator parameters\n",
    "    accumulator.setEventContribution(0.25)\n",
    "    accumulator.setNeutralPotential(0.5)\n",
    "    accumulator.setMinPotential(0.0)\n",
    "    accumulator.setMaxPotential(1.0)\n",
    "    accumulator.setDecayFunction(dv.Accumulator.Decay.LINEAR)\n",
    "    accumulator.setDecayParam(1e-6)\n",
    "    accumulator.setSynchronousDecay(False)\n",
    "    accumulator.setIgnorePolarity(False)\n",
    "    \n",
    "    # Create preview window\n",
    "    cv2.namedWindow(\"Events Preview\", cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # Create event slicer\n",
    "    slicer = dv.EventStreamSlicer()\n",
    "    \n",
    "    # Frame counter\n",
    "    frame_counter = 0\n",
    "    \n",
    "    def accumulate_events(event_slice):\n",
    "        nonlocal frame_counter\n",
    "        \n",
    "        # Pass event slice to accumulator\n",
    "        accumulator.accept(event_slice)\n",
    "        \n",
    "        # Generate frame\n",
    "        frame = accumulator.generateFrame()\n",
    "        \n",
    "        # Increment frame counter\n",
    "        frame_counter += 1\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow(\"Events Preview\", frame.image)\n",
    "        cv2.waitKey(2)\n",
    "    \n",
    "    # Set time interval\n",
    "    slicer.doEveryTimeInterval(datetime.timedelta(milliseconds=interval_ms), accumulate_events)\n",
    "    \n",
    "    print(\"Starting event data playback...\")\n",
    "    \n",
    "    # Get event data\n",
    "    # We need to convert PyTorch tensor to event format that dv library can process\n",
    "    # Process events in batches, 1000 events per batch\n",
    "    batch_size = 1000\n",
    "    total_events = len(events)\n",
    "    \n",
    "    for i in range(0, total_events, batch_size):\n",
    "        # Get current batch of events\n",
    "        batch_events = events[i:min(i+batch_size, total_events)]\n",
    "        \n",
    "        # Convert to format that dv library can process\n",
    "        batch = dv.EventStore()\n",
    "        for j in range(len(batch_events)):\n",
    "            event = batch_events[j]\n",
    "            x = int(event[0].item())\n",
    "            y = int(event[1].item())\n",
    "            timestamp = int(event[2].item())\n",
    "            polarity = int(event[3].item())\n",
    "            batch.push_back(dv.Event(x, y, timestamp, polarity))\n",
    "        \n",
    "        # Pass events to slicer\n",
    "        slicer.accept(batch)\n",
    "        \n",
    "        # Check if 'q' key is pressed to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    print(f\"Total frames: {frame_counter}\")\n",
    "    print(\"Event playback completed\")\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Play events\n",
    "play_filtered_events(filtered_events_dv, 33, (DV_BOX_SIZE_FOR_EVENT, DV_BOX_SIZE_FOR_EVENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k_search_funciton.interval_fit as interval_fit\n",
    "import importlib\n",
    "importlib.reload(interval_fit)\n",
    "\n",
    "num_pixels_dv, dt_dv, mu_dv, sigma_dv = interval_fit.analyze_per_pixel_event_intervals_combined(\n",
    "    events=filtered_events_dv,\n",
    "    min_events_per_pixel=10,         # For example, at least 10 events per pixel\n",
    "    max_dt_us_for_plot=100000,          # For example, only plot intervals below 200 microseconds\n",
    "    plot_bins=100,\n",
    "    type='DV'\n",
    ")\n",
    "plt.show()  # Display the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
